{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fbbc5ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\sahla\\anaconda3\\lib\\site-packages (1.11.0)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\sahla\\anaconda3\\lib\\site-packages (from torch) (3.10.0.2)\n",
      "Requirement already satisfied: nltk in c:\\users\\sahla\\anaconda3\\lib\\site-packages (3.6.5)\n",
      "Requirement already satisfied: click in c:\\users\\sahla\\anaconda3\\lib\\site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\sahla\\anaconda3\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\sahla\\anaconda3\\lib\\site-packages (from nltk) (2021.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sahla\\anaconda3\\lib\\site-packages (from nltk) (4.62.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\sahla\\anaconda3\\lib\\site-packages (from tqdm->nltk) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import json\n",
    "\n",
    "!pip3 install torch\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "!pip3 install nltk\n",
    "import nltk\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "020011a4-45e3-4747-8a08-099c1b483491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intents': [{'tag': 'greeting', 'patterns': ['Hi', 'Hey', 'How are you', 'Hello,Is anyone there?', 'Hello', 'Good day'], 'responses': ['Hey :)', 'Hello, thanks for visiting', 'Hi there, what can I do for you?', 'Hi there, how can I help?', 'Welcome to ticket booking service']}, {'tag': 'goodbye', 'patterns': ['Bye', 'See you later', 'Goodbye'], 'responses': ['See you later, thanks for visiting', 'Have a nice day', 'Bye! Come back again soon.', 'Have a good day', 'Have a great rest of the day', 'Have a great rest of the evening']}, {'tag': 'thanks', 'patterns': ['Thanks', 'Thank you', \"That's helpful\", \"Thank's a lot!\"], 'responses': ['Happy to help!', 'Any time!', 'My pleasure', 'Is there anything else I can help you with?']}, {'tag': 'ticket type', 'patterns': ['What type of tickets are available?', 'How many gold tickets are available?', 'How many platinum tickets are available?', 'How many silver tickets are available?', 'How many gold seats are there?', 'How many silver seats are there?', 'How many platinum seats are there?'], 'responses': ['Which type of ticket do you want?', 'We have platinum,gold and silver seats', 'We have 1 gold ticket left', 'We have 2 gold tickets', 'We have 3 gold tickets', 'We have some gold tickets left', 'We have 1 platinum ticket left', 'We have 2 platinum ticket', 'We have 3 platinum ticket', 'We have some platinum tickets available', 'We have 1 silver ticket left', 'We have 2 silver ticket', 'We have 3 silver ticket', 'We have some silver tickets available']}, {'tag': 'tickets', 'patterns': ['what are the ticket prices?', 'How many tickets are available?', 'Is there a student discount available?', 'How many tickets can I book with 100 pounds? '], 'responses': ['Which type of ticket do you want?', 'The prices range from 20-50 pounds', 'Yes, student discount is available']}, {'tag': 'time slot', 'patterns': ['Which time slots are available for movie Mission Impossible?', 'Which time slots are available for movie K.G.F 2?', 'Which time slots are available for movie Moonfall?', 'Which time slots are available for movie The contractor?', 'Which time slots are available for movie Ambulance?', 'Which time slots are available for movie RRR?', 'Which time slots are available for movie The Spiderman?'], 'responses': ['The time slot for K.G.F 2  are: ', 'The time slot for Moonfall  are: ', 'The time slot for The contractor are: ', 'The time slot for Ambulance are: ', 'The time slot for RRR are: ', 'The time slot for The Spiderman are:', 'The time slot for movie Mission Impossible are:']}, {'tag': 'movie type', 'patterns': ['Which movies are being shown?'], 'responses': ['The movies that are being shown are Mission Impossible, K.G.F 2, Moonfall, The contractor, Ambulance, RRR, The Spiderman', \"Please check your 'Now showing' to view the options of movies\"]}, {'tag': 'time', 'patterns': ['What is the starting time for the movie?', 'what time should I reach for the movie?'], 'response': ['The time is mentioned on the ticket', 'Please arrive 15 minutes before the mentioned time on the ticket', '']}, {'tag': 'payments', 'patterns': ['Do you take credit card?', 'Do you accept Mastercard?', 'Are you cash only?', 'Which payment options are accepted?'], 'response': ['We accept both card and cash', 'Mastercard is accepted']}, {'tag': 'error', 'patterns': [' The payment is not being accepted', 'I cannot figure out a way to book the tickets', 'The app has crashed after payment', 'I completed the booking, but I havent recieved my tickets yet.'], 'response': ['Please be patient, I am transferring you to a real agent ']}]}\n"
     ]
    }
   ],
   "source": [
    "with open('dataset.json') as t:\n",
    "    dftext = json.load(t)\n",
    "print(dftext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa8d6f0a-2886-4bd1-92d7-95eec5ac549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_wds = []\n",
    "tgs = []\n",
    "x_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc36a485-4aca-4431-b96a-637754a0fb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = TreebankWordTokenizer()\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "for intt in dftext['intents']:\n",
    "    tg = intt['tag']\n",
    "    tgs.append(tg)\n",
    "    for patrn in intt['patterns']:\n",
    "        wtk = tokenizer.tokenize(patrn)\n",
    "        all_wds.extend(wtk)\n",
    "        x_y.append((wtk, tg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d5bd6de-5f86-4bce-bc07-50597e7de2a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 patterns\n",
      "10 tags: ['error', 'goodbye', 'greeting', 'movie type', 'payments', 'thanks', 'ticket type', 'tickets', 'time', 'time slot']\n",
      "86 Stemmed unique words: [\"'s\", ',', '100', '2', 'a', 'accept', 'after', 'ambul', 'anyon', 'app', 'are', 'avail', 'be', 'book', 'but', 'bye', 'can', 'card', 'cash', 'complet', 'contractor', 'crash', 'credit', 'day', 'discount', 'do', 'figur', 'for', 'gold', 'good', 'goodby', 'ha', 'havent', 'hello', 'help', 'hey', 'hi', 'how', 'i', 'imposs', 'is', 'k.g.f', 'later', 'lot', 'mani', 'mastercard', 'mission', 'moonfal', 'movi', 'my', 'not', 'of', 'onli', 'option', 'out', 'payment', 'platinum', 'pound', 'price', 'reach', 'reciev', 'rrr', 'seat', 'see', 'should', 'shown', 'silver', 'slot', 'spiderman', 'start', 'student', 'take', 'thank', 'that', 'the', 'there', 'ticket', 'time', 'to', 'type', 'way', 'what', 'which', 'with', 'yet', 'you']\n"
     ]
    }
   ],
   "source": [
    "ignore_syntax = [\"?\",\"/\",\".\",\"!\", \"@\", \"#\", \"$\"]\n",
    "all_wds = [stemmer.stem(wtk) for wtk in all_wds if wtk not in ignore_syntax]\n",
    "\n",
    "all_wds = sorted(set(all_wds))\n",
    "tgs = sorted(set(tgs))\n",
    "print(len(x_y), \"patterns\")\n",
    "print(len(tgs), \"tags:\", tgs)\n",
    "print(len(all_wds), \"Stemmed unique words:\", all_wds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62aff849-e9cc-43ac-96e3-b5e410c4d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Bg_Wrds(token_sntce, wrds):\n",
    "    sntce_wrds = [stemmer.stem(word) for word in token_sntce]\n",
    "\n",
    "    Bg = np.zeros(len(wrds), dtype=np.float32)\n",
    "    for indx, r in enumerate(wrds):\n",
    "        if r in sntce_wrds: \n",
    "            Bg[indx] = 1\n",
    "\n",
    "    return Bg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6efce88-622b-4dc3-bea4-dee3bfea3ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_training = []\n",
    "y_training = []\n",
    "for (patrn_sntce, tg) in x_y:\n",
    "    \n",
    "    Bg = Bg_Wrds(patrn_sntce, all_wds)\n",
    "    X_training.append(Bg)\n",
    "    lbl = tgs.index(tg)\n",
    "    y_training.append(lbl)\n",
    "\n",
    "X_training =np.array(X_training)\n",
    "y_training =np.array(y_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b894ae1-3062-4cb9-837e-ec63e926a114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 10\n"
     ]
    }
   ],
   "source": [
    "numepochs = 1000\n",
    "batch_size = 8\n",
    "Rate_of_learning = 0.001\n",
    "size_inputs = len(X_training[0])\n",
    "hide_size = 8\n",
    "size_of_output = len(tgs)\n",
    "print(size_inputs, size_of_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eec1878e-63df-400e-90de-3f12a611b194",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNet(nn.Module):\n",
    "    def __init__(self, size_inputs, hide_size, numclass):\n",
    "        super(NNet, self).__init__()\n",
    "        self.l1 = nn.Linear(size_inputs, hide_size) \n",
    "        self.l2 = nn.Linear(hide_size, hide_size) \n",
    "        self.l3 = nn.Linear(hide_size, numclass)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, a):\n",
    "        outpt = self.l1(a)\n",
    "        outpt = self.relu(outpt)\n",
    "        outpt = self.l2(outpt)\n",
    "        outpt = self.relu(outpt)\n",
    "        outpt = self.l3(outpt)\n",
    "        return outpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c3f8139-7f7b-4684-9a9e-505b5adc90f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.3212\n",
      "Epoch [200/1000], Loss: 0.1134\n",
      "Epoch [300/1000], Loss: 0.0422\n",
      "Epoch [400/1000], Loss: 0.0082\n",
      "Epoch [500/1000], Loss: 0.0128\n",
      "Epoch [600/1000], Loss: 0.0012\n",
      "Epoch [700/1000], Loss: 0.0003\n",
      "Epoch [800/1000], Loss: 0.0001\n",
      "Epoch [900/1000], Loss: 0.0001\n",
      "Epoch [1000/1000], Loss: 0.0004\n",
      "final loss: 0.0004\n",
      "training complete. file saved to data.pth\n"
     ]
    }
   ],
   "source": [
    "class ChatDatas(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n_samples = len(X_training)\n",
    "        self.x_datas = X_training\n",
    "        self.y_datas = y_training\n",
    "\n",
    "    def __getitem__(self, indx):\n",
    "        return self.x_datas[indx], self.y_datas[indx]\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "dataset = ChatDatas()\n",
    "training_load = DataLoader(dataset=dataset,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=0)\n",
    "\n",
    "devices = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model1 = NNet(size_inputs, hide_size, size_of_output).to(devices)\n",
    "\n",
    "\n",
    "criteria = nn.CrossEntropyLoss()\n",
    "optimize = torch.optim.Adam(model1.parameters(), lr=Rate_of_learning)\n",
    "\n",
    "\n",
    "for epoch in range(numepochs):\n",
    "    for (word, label) in training_load:\n",
    "        words = word.to(devices)\n",
    "        label = label.to(dtype=torch.long).to(devices)\n",
    "        \n",
    "    \n",
    "        otputs = model1(words)\n",
    "        losses = criteria(otputs, label)\n",
    "        \n",
    "        optimize.zero_grad()\n",
    "        losses.backward()\n",
    "        optimize.step()\n",
    "        \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print (f'Epoch [{epoch+1}/{numepochs}], Loss: {losses.item():.4f}')\n",
    "\n",
    "\n",
    "print(f'final loss: {losses.item():.4f}')\n",
    "\n",
    "data = {\n",
    "\"model_state\": model1.state_dict(),\n",
    "\"input_size\": size_inputs,\n",
    "\"hidden_size\": hide_size,\n",
    "\"size_of_output\": size_of_output,\n",
    "\"all_words\": all_wds,\n",
    "\"tgs\": tgs\n",
    "}\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "torch.save(data, FILE)\n",
    "\n",
    "print(f'training complete. file saved to {FILE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4de99ab8-f25c-4961-91c6-a8b291072ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's chat! (type 'quit' to exit)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27100/3046710521.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Let's chat! (type 'quit' to exit)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0msentnc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msentnc\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"quit\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sahla\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1004\u001b[0m                 \u001b[1;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m             )\n\u001b[1;32m-> 1006\u001b[1;33m         return self._input_request(\n\u001b[0m\u001b[0;32m   1007\u001b[0m             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"shell\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\sahla\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1049\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m                 \u001b[1;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1051\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Interrupted by user\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1052\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1053\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Invalid Message:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "with open('dataset.json', 'r') as jason_datas:\n",
    "    intents = json.load(jason_datas)\n",
    "\n",
    "FILE = \"data.pth\"\n",
    "data = torch.load(FILE)\n",
    "\n",
    "size_inputs = data[\"input_size\"]\n",
    "hide_size = data[\"hidden_size\"]\n",
    "size_of_output = data[\"size_of_output\"]\n",
    "all_wds = data['all_words']\n",
    "tgs = data['tgs']\n",
    "model_state = data[\"model_state\"]\n",
    "\n",
    "model = NNet(size_inputs, hide_size, size_of_output\n",
    ")\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "\n",
    "bot_name = \"Sam\"\n",
    "print(\"Let's chat! (type 'quit' to exit)\")\n",
    "while True:\n",
    "    sentnc = input(\"You: \")\n",
    "    if sentnc == \"quit\":\n",
    "        break\n",
    "\n",
    "    sentnc = tokenizer.tokenize(sentnc)\n",
    "    X = Bg_Wrds(sentnc, all_wds)\n",
    "    X = X.reshape(1, X.shape[0])\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "\n",
    "    outpt = model(X)\n",
    "    _, predicted = torch.max(outpt, dim=1)\n",
    "\n",
    "    tag = tgs[predicted.item()]\n",
    "\n",
    "    probs = torch.softmax(outpt, dim=1)\n",
    "    prob = probs[0][predicted.item()]\n",
    "    if prob.item() > 0.75:\n",
    "        for intent in intents['intents']:\n",
    "            if tag == intent[\"tag\"]:\n",
    "                print(f\"{bot_name}: {random.choice(intent['responses'])}\")\n",
    "    else:\n",
    "        print(f\"{bot_name}: I do not understand...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a608f9d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3a50193da942bf77f0c1ba24b19bd8604e132919c178ad26ac8b7e94fefd61c9"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
